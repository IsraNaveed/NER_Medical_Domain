{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "6aUp_OGD8H_C",
        "outputId": "a0f4cf19-9765-43ae-a409-b4796f408270"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e9df71db90e1>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Define the NER model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/training/example.pyx\u001b[0m in \u001b[0;36mspacy.training.example.Example.from_dict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: from_dict() takes exactly 2 positional arguments (1 given)"
          ]
        }
      ],
      "source": [
        "# pip install spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "import random\n",
        "from spacy.training.example import Example\n",
        "from spacy.util import minibatch\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample dataset (replace this with your extended dataset)\n",
        "dataset = [\n",
        "    \"Mrs. May visited Leeds General Infirmary hospital which is located near Burley Road.\",\n",
        "    \"She was not feeling well and had an appointment with Dr. Ray Johnson.\"\n",
        "    # ... (add more sentences)\n",
        "]\n",
        "\n",
        "# Assuming 80% for training and 20% for testing\n",
        "split = int(0.8 * len(dataset))\n",
        "train_data = dataset[:split]\n",
        "test_data = dataset[split:]\n",
        "\n",
        "# Prepare training data\n",
        "training_data = []\n",
        "for sentence in train_data:\n",
        "    doc = nlp(sentence)\n",
        "    entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
        "    example = Example.from_dict({\"text\": sentence , \"entities\": entities})\n",
        "    training_data.append(example)\n",
        "# Define the NER model\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add labels for medical entities\n",
        "labels = [\"Disease\", \"Medication\", \"Procedure\", \"Symptom\", \"Location\", \"Doctor\", \"Date\", \"Pharmacy\"]\n",
        "\n",
        "for label in labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "# Disable other pipelines during training to speed up training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    # Training the NER model\n",
        "    for epoch in range(10):  # You may need to adjust the number of epochs\n",
        "        random.shuffle(training_data)\n",
        "        losses = {}\n",
        "\n",
        "        for batch in minibatch(training_data, size=8):\n",
        "            examples, _ = zip(*batch)\n",
        "            nlp.update(examples, drop=0.5, losses=losses)\n",
        "\n",
        "        print(losses)\n",
        "# Evaluate the model\n",
        "test_loss = 0.0\n",
        "\n",
        "for sentence in test_data:\n",
        "    doc = nlp(sentence)\n",
        "    gold_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
        "    gold_example = Example.from_dict({\"text\": sentence, \"entities\": gold_entities})\n",
        "    loss = nlp.evaluate([gold_example])\n",
        "    test_loss += loss\n",
        "\n",
        "avg_test_loss = test_loss / len(test_data)\n",
        "print(f\"Average test loss: {avg_test_loss}\")\n"
      ]
    }
  ]
}